{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import joblib\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import glob\n",
    "import sklearn\n",
    "from gx_spectral.feature import roi, spectrum\n",
    "import spectral\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.signal import savgol_filter      # filter\n",
    "\n",
    "\n",
    "plt.rcParams['figure.max_open_warning'] = 0      # Turn off warning\n",
    "\n",
    "# Font configuration\n",
    "plt.rcParams['font.family'] = 'Noto Serif SC'\n",
    "\"\"\"Check fonts in matplotlib\n",
    "from matplotlib import font_manager\n",
    "for font in font_manager.fontManager.ttflist:\n",
    "    print(font.name, '-', font.name)\n",
    "\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 一、取得训练数据\n",
    "1. 从文档中提取图片，图片按照文件夹被分类\n",
    "2. 将四个通道合成多光谱图像\n",
    "3. 阈值分割，取得感兴趣的区域（咖啡豆），得到图像 `mask`\n",
    "4. 在 `mask` 上寻找轮廓（contours），得到目标掩膜（`target_mask`）\n",
    "5. 利用掩膜，从原始多光谱图像中提取该区域的多光谱均值（即特征），并记录对应的类别\n",
    "其中 `msi[target_mask]` 会返回这个掩膜中 `True` 的所有像素点在多光谱图像中的值\n",
    "6. 取得该区域在 4 个通道上的平均值，用作该目标的光谱特征。\n",
    "\n",
    "同时计算每颗咖啡豆的 GLCM 信息，存储于 `glcm_features`，一共是 80 * 288 的 NumPy 数组\n",
    "\n",
    "其中 80 粒咖啡豆；4 通道 * 3 distances * 4 angles * 6 properties = 288"
   ],
   "id": "2f1e3fee2e870a1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_root = r'D:\\Work_Dr\\Coffee_bean\\Source'\n",
    "classes = os.listdir(data_root)\n",
    "\n",
    "\n",
    "\n",
    "# 保存光谱数据与其对应标签\n",
    "specs = []\n",
    "sg_specs = []\n",
    "snv_specs = []\n",
    "FD_specs = []\n",
    "SD_specs = []\n",
    "labels = []\n",
    "\n",
    "glcm_features = []\n",
    "\n",
    "# GLCM 参数\n",
    "distances = [1, 3, 5]\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(data_root, cls)\n",
    "    img_names = sorted(os.listdir(cls_path))\n",
    "    # Save MSI (Multiple Spectrum Image)\n",
    "    msi = []\n",
    "    for name in img_names:\n",
    "        img_path = os.path.join(cls_path, name)\n",
    "        print(img_path)\n",
    "        img = cv.imread(img_path, cv.IMREAD_UNCHANGED)\n",
    "        # Blend 4 channels into MSI\n",
    "        msi.append(img)\n",
    "    msi = np.transpose(np.array(msi), (1, 2, 0))\n",
    "    # 使用 MSI 的第四通道用于阈值分割\n",
    "    im_seg = msi[:, :, 3]\n",
    "    im_seg = (im_seg / im_seg.max() * 255).astype(np.uint8)     # idk\n",
    "    # 二值化图像，用于提取轮廓\n",
    "    mask = cv.threshold(im_seg, 100, 255, cv.THRESH_BINARY)[1]\n",
    "    # 展示咖啡豆轮廓\n",
    "    plt.figure()\n",
    "    plt.imshow(mask)\n",
    "    # 寻找咖啡豆轮廓\n",
    "    contours, hierarchy = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for cont in contours:\n",
    "        target_mask = np.zeros_like(im_seg)\n",
    "        perimeter = cv.arcLength(cont, True)\n",
    "        if perimeter < 50:\n",
    "            # Skip if area is too small\n",
    "            continue\n",
    "        cv.drawContours(target_mask, [cont], 0, (255, 255, 255), -1)\n",
    "        plt.figure()\n",
    "        plt.imshow(target_mask)\n",
    "        # 将目标区域的掩膜转换为布尔类型（True 表示目标区域，False 表示背景）\n",
    "        target_mask = target_mask.astype(bool)\n",
    "        # 取得该区域在 4 个通道上的平均光谱值\n",
    "        spec = np.mean(msi[target_mask], axis=(0))\n",
    "        specs.append(spec)\n",
    "        labels.append(cls)\n",
    "\n",
    "        # Calculate GLCM\n",
    "        glcm_feats = []\n",
    "        for channel in range(4):\n",
    "            # 提取单个通道图像\n",
    "            img_channel = msi[:, :, channel]\n",
    "            \n",
    "            # 应用掩码并转换为8位灰度图像\n",
    "            masked_img = np.zeros_like(img_channel)\n",
    "            masked_img[target_mask] = img_channel[target_mask]\n",
    "            masked_img = (masked_img / masked_img.max() * 255).astype(np.uint8)\n",
    "\n",
    "            # 获取包含咖啡豆的最小矩形区域（减少计算量）\n",
    "            rows, cols = np.where(target_mask)\n",
    "            if len(rows) == 0 or len(cols) == 0:\n",
    "                continue\n",
    "\n",
    "            min_row, max_row = np.min(rows), np.max(rows)\n",
    "            min_col, max_col = np.min(cols), np.max(cols)\n",
    "            roi = masked_img[min_row:max_row+1, min_col:max_col+1]\n",
    "\n",
    "            # 计算GLCM矩阵\n",
    "            glcm = graycomatrix(roi, distances=distances, angles=angles,\n",
    "                               levels=256, symmetric=True, normed=True)\n",
    "\n",
    "            # 提取GLCM属性\n",
    "            for prop in properties:\n",
    "                feature = graycoprops(glcm, prop).flatten()\n",
    "                glcm_feats.extend(feature)\n",
    "\n",
    "        # 添加GLCM特征到列表中\n",
    "        glcm_features.append(np.array(glcm_feats))\n",
    "\n",
    "        # break     # 取消注释以单词计算\n",
    "\n",
    "specs = np.array(specs)\n",
    "labels = np.array(labels)\n",
    "glcm_features = np.array(glcm_features)\n",
    "print(specs.shape, labels.shape)\n",
    "print(glcm_features.shape)"
   ],
   "id": "50848fdcadbf9266",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 二、光谱预处理\n",
    "使用几种常见的预处理方法处理光谱数据\n",
    "1. Savitzky-Golay 滤波器\n",
    "2. 标准正态变换 SNV\n",
    "3. 一阶导数处理\n",
    "4. 二阶导数处理"
   ],
   "id": "76fd040220b7b639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sg_filter(specs, windows_length=11, polyorder=3):\n",
    "    spec_val, num_channels = specs.shape\n",
    "    print(specs.shape)\n",
    "    specs_filtered = np.copy(specs)\n",
    "    for i in range(num_channels):\n",
    "        specs_filtered[:, i] = savgol_filter(specs[:, i], windows_length, polyorder)\n",
    "\n",
    "    return specs_filtered\n",
    "\n",
    "def snv_filter(specs):\n",
    "    mean = np.mean(specs, axis=0)\n",
    "    std = np.std(specs, axis=0)\n",
    "    std[std == 0] = 1\n",
    "    snv_specs = (specs - mean) / std\n",
    "    return snv_specs\n",
    "\n",
    "def first_derivative(specs):\n",
    "    FD_specs = np.zeros_like(specs)\n",
    "    for i in range(specs.shape[1]):  # 遍历每个光谱通道\n",
    "        FD_specs[:, i] = np.gradient(specs[:, i])  # 计算一阶导数\n",
    "    return FD_specs\n",
    "\n",
    "def second_derivative(specs):\n",
    "    SD_specs = np.zeros_like(specs)\n",
    "    for i in range(specs.shape[1]):  # 遍历每个光谱通道\n",
    "        SD_specs[:, i] = np.gradient(np.gradient(specs[:, i]))  # 计算二阶导数\n",
    "    return SD_specs\n",
    "\n",
    "sg_specs = sg_filter(specs)\n",
    "snv_specs = snv_filter(specs)\n",
    "FD_specs = first_derivative(specs)\n",
    "SD_specs = second_derivative(specs)\n",
    "\n"
   ],
   "id": "5c6a06161463580e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 展示光谱图像",
   "id": "77516fedf017f591"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gx_spectral.visualization import drawer\n",
    "def spec_chart_display(specs, labels, title):\n",
    "    spec_pos = [450, 555, 660, 850]\n",
    "    spec_pos = np.array(spec_pos, dtype=str)\n",
    "    img = drawer.show_specs_class(spec_pos, specs, labels, title=title)\n",
    "    return\n",
    "\n",
    "spec_chart_display(specs, labels, \"Reflective Rate - None\")\n",
    "spec_chart_display(sg_specs, labels, \"Reflective Rate - Savitzky-Golay Filtered\")\n",
    "spec_chart_display(snv_specs, labels, \"Reflective Rate - SNV\")\n",
    "spec_chart_display(FD_specs, labels, \"Reflective Rate - First Derivative\")\n",
    "spec_chart_display(SD_specs, labels, \"Reflective Rate - Second Derivative\")"
   ],
   "id": "8de2004da52507d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 三、建模分析\n",
    "### 1. Prerequisite\n",
    "定义一个网格搜索函数 `grid_search` 用于找到最佳参数"
   ],
   "id": "85fec069e21a62a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "def grid_search(X_train, y_train, savePath='./svm2'):\n",
    "    tuned_parameters = [\n",
    "    {\"kernel\": [\"rbf\", 'linear'], \"gamma\": 1/np.power(10, np.arange(5)), \"C\": np.power(10, np.arange(5))},]\n",
    "    param_grid = {\n",
    "        'pca__n_components': np.arange(2,5),\n",
    "        'clf__C': np.power(10, np.arange(5)),\n",
    "        'clf__gamma': 1/np.power(10, np.arange(5)),\n",
    "        'clf__kernel': [\"rbf\", 'linear']\n",
    "    }\n",
    "    score = 'accuracy'\n",
    "    # score = 'neg_mean_squared_error'\n",
    "    # scaler = StandardScaler().fit(X_train)\n",
    "    # X_scaled = scaler.transform(X_train)\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=2)), ('clf', svm.SVC())])\n",
    "    clf = GridSearchCV(pipeline, param_grid, scoring=score, cv=5)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Best score:\",clf.best_score_)\n",
    "    #保存最优参数\n",
    "    paraFilePath = os.path.join(savePath, 'best_model_parameters.json')\n",
    "#     with open(paraFilePath, 'w+') as f:\n",
    "#         json.dump(clf.best_params_, f)\n",
    "\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    return clf.best_estimator_\n"
   ],
   "id": "4a40e119c88b71c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. 取得带有 GLCM 的数据\n",
    "使用 `np.concatenate` 拼接矩阵"
   ],
   "id": "3bb30f942ac4b746"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "specs_with_GLCM = np.concatenate((specs, glcm_features), axis = 1)\n",
    "# snv_specs_with_GLCM = np.concatenate((snv_specs, glcm_features), axis = 1)\n",
    "# FD_specs_with_GLCM = np.concatenate((FD_specs, glcm_features), axis = 1)\n",
    "# SD_specs_with_GLCM = np.concatenate((SD_specs, glcm_features), axis = 1)\n",
    "\n",
    "# Validate\n",
    "print(specs_with_GLCM.shape)\n",
    "# print(snv_specs_with_GLCM.shape)\n",
    "# print(FD_specs_with_GLCM.shape)\n",
    "# print(SD_specs_with_GLCM.shape)"
   ],
   "id": "b68db2f320280fd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Train without GLCM by SVM",
   "id": "39a843facc5c97cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gx_spectral.visualization import drawer\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# pca = PCA(n_components=3)\n",
    "X = SD_specs\n",
    "y = labels\n",
    "strKFold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    # PCA(n_components=5),\n",
    "    # RandomForestClassifier(),\n",
    "    svm.SVC(kernel='linear', C=1000, gamma=0.001)\n",
    ")\n",
    "\n",
    "# 自动划分数据集进行建模评估\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9, stratify=y)\n",
    "# model = grid_search(X_train, y_train)\n",
    "scores = cross_val_score(model,X,y,cv=strKFold)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "print(model)\n",
    "model.fit(X_train,y_train)\n",
    "score_res = model.score(X_train,y_train)\n",
    "print(\"The train score of model is : %f\"%score_res)\n",
    "score_res = model.score(X_test,y_test)\n",
    "print(\"The test score of model is : %f\"%score_res)\n",
    "y_pred = model.predict(X_test)\n",
    "img, report = drawer.show_confusion_matrix(y_test, y_pred)\n",
    "cv.imwrite('Plots/Prediction/prediction_None_SVM.png', img)\n",
    "# 将report保存成本地文件\n",
    "pd.DataFrame(report).transpose().to_csv(\"report_None_SVM.csv\", index= True, float_format='%.2f')"
   ],
   "id": "61e71e539734126c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2 Train with GLCM by SVM",
   "id": "b1aca7fc5721d486"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = specs_with_GLCM\n",
    "y = labels\n",
    "strKFold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    # PCA(n_components=5),\n",
    "    # RandomForestClassifier(),\n",
    "    svm.SVC(kernel='linear', C=1000, gamma=0.001)\n",
    ")\n",
    "\n",
    "# 自动划分数据集进行建模评估\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9, stratify=y)\n",
    "# model = grid_search(X_train, y_train)\n",
    "scores = cross_val_score(model,X,y,cv=strKFold)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "print(model)\n",
    "model.fit(X_train,y_train)\n",
    "score_res = model.score(X_train,y_train)\n",
    "print(\"The train score of model is : %f\"%score_res)\n",
    "score_res = model.score(X_test,y_test)\n",
    "print(\"The test score of model is : %f\"%score_res)\n",
    "y_pred = model.predict(X_test)\n",
    "img, report = drawer.show_confusion_matrix(y_test, y_pred)\n",
    "cv.imwrite('Plots/Prediction/prediction_GLCM_SVM.png', img)\n",
    "# 将report保存成本地文件\n",
    "pd.DataFrame(report).transpose().to_csv(\"report_GLCM_SVM.csv\", index= True, float_format='%.2f')"
   ],
   "id": "6b485b0c72c65bdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Train without GLCM by KNN",
   "id": "59509fa06a2417d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = SD_specs\n",
    "y = labels\n",
    "strKFold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier()\n",
    ")\n",
    "\n",
    "# 自动划分数据集进行建模评估\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9, stratify=y)\n",
    "\n",
    "scores = cross_val_score(model,X,y,cv=strKFold)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "# 使用 GridSearch 网格搜索得到最优 K 值\n",
    "# 设置参数网络，检索（1, 20）内最佳的 k 参数\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': range(1, 20)\n",
    "}\n",
    "\n",
    "grid_search_KNN = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search_KNN.fit(X_train, y_train)\n",
    "\n",
    "print(f\"最优的K值: {grid_search_KNN.best_params_['kneighborsclassifier__n_neighbors']}\")\n",
    "\n",
    "\n",
    "print(model)\n",
    "model.fit(X_train,y_train)\n",
    "score_res = model.score(X_train,y_train)\n",
    "print(\"The train score of model is : %f\"%score_res)\n",
    "score_res = model.score(X_test,y_test)\n",
    "print(\"The test score of model is : %f\"%score_res)\n",
    "y_pred = model.predict(X_test)\n",
    "img, report = drawer.show_confusion_matrix(y_test, y_pred)\n",
    "cv.imwrite('Plots/Prediction/prediction_None_KNN.png', img)\n",
    "# 将report保存成本地文件\n",
    "pd.DataFrame(report).transpose().to_csv(\"report_None_KNN.csv\", index= True, float_format='%.2f')"
   ],
   "id": "839ce23f820f5995",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2 Train with GLCM by KNN",
   "id": "d3d7ee82cc49542b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = specs_with_GLCM\n",
    "y = labels\n",
    "strKFold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier()\n",
    ")\n",
    "\n",
    "# 自动划分数据集进行建模评估\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9, stratify=y)\n",
    "\n",
    "scores = cross_val_score(model,X,y,cv=strKFold)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "# 使用 GridSearch 网格搜索得到最优 K 值\n",
    "# 设置参数网络，检索（1, 20）内最佳的 k 参数\n",
    "param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': range(1, 20)\n",
    "}\n",
    "\n",
    "grid_search_KNN = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search_KNN.fit(X_train, y_train)\n",
    "\n",
    "print(f\"最优的K值: {grid_search_KNN.best_params_['kneighborsclassifier__n_neighbors']}\")\n",
    "\n",
    "\n",
    "print(model)\n",
    "model.fit(X_train,y_train)\n",
    "score_res = model.score(X_train,y_train)\n",
    "print(\"The train score of model is : %f\"%score_res)\n",
    "score_res = model.score(X_test,y_test)\n",
    "print(\"The test score of model is : %f\"%score_res)\n",
    "y_pred = model.predict(X_test)\n",
    "img, report = drawer.show_confusion_matrix(y_test, y_pred)\n",
    "cv.imwrite('Plots/Prediction/prediction_GLCM_KNN.png', img)\n",
    "# 将 report 保存成本地文件\n",
    "pd.DataFrame(report).transpose().to_csv(\"report_GLCM_KNN.csv\", index= True, float_format='%.2f')"
   ],
   "id": "f87972acdccbefb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1 Train without GLCM by NB",
   "id": "68959ee55d870dbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = SD_specs\n",
    "y = labels\n",
    "\n",
    "strKFold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "# 自动划分数据集进行建模评估\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9, stratify=y)\n",
    "scores = cross_val_score(model,X,y,cv=strKFold)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "# 网格搜索参数\n",
    "param_grid = {\n",
    "    'gaussiannb__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "grid_search_NB = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                     # 5折交叉验证\n",
    "    scoring='accuracy',       # 以准确率作为评估指标\n",
    "    n_jobs=-1                  # 用所有CPU核加速\n",
    ")\n",
    "\n",
    "grid_search_NB.fit(X, y)\n",
    "\n",
    "print(f\"Best parameter: {grid_search_NB.best_params_}\")\n",
    "\n",
    "print(model)\n",
    "model.fit(X_train,y_train)\n",
    "score_res = model.score(X_train,y_train)\n",
    "print(\"The train score of model is : %f\"%score_res)\n",
    "score_res = model.score(X_test,y_test)\n",
    "print(\"The test score of model is : %f\"%score_res)\n",
    "y_pred = model.predict(X_test)\n",
    "img, report = drawer.show_confusion_matrix(y_test, y_pred)\n",
    "cv.imwrite('Plots/Prediction/prediction_None_NB.png', img)\n",
    "# 将report保存成本地文件\n",
    "pd.DataFrame(report).transpose().to_csv(\"report_None_NB.csv\", index= True, float_format='%.2f')"
   ],
   "id": "58b51f91deaa065a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Train with GLCM by NB\n",
   "id": "99fa7fcaef468621"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = specs_with_GLCM\n",
    "y = labels\n",
    "\n",
    "strKFold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "# 自动划分数据集进行建模评估\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9, stratify=y)\n",
    "scores = cross_val_score(model,X,y,cv=strKFold)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "# 网格搜索参数\n",
    "param_grid = {\n",
    "    'gaussiannb__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "grid_search_NB = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                     # 5折交叉验证\n",
    "    scoring='accuracy',       # 以准确率作为评估指标\n",
    "    n_jobs=-1                  # 用所有CPU核加速\n",
    ")\n",
    "\n",
    "grid_search_NB.fit(X, y)\n",
    "\n",
    "print(f\"Best parameter: {grid_search_NB.best_params_}\")\n",
    "\n",
    "print(model)\n",
    "model.fit(X_train,y_train)\n",
    "score_res = model.score(X_train,y_train)\n",
    "print(\"The train score of model is : %f\"%score_res)\n",
    "score_res = model.score(X_test,y_test)\n",
    "print(\"The test score of model is : %f\"%score_res)\n",
    "y_pred = model.predict(X_test)\n",
    "img, report = drawer.show_confusion_matrix(y_test, y_pred)\n",
    "cv.imwrite('Plots/Prediction/prediction_GLCM_NB.png', img)\n",
    "# 将report保存成本地文件\n",
    "pd.DataFrame(report).transpose().to_csv(\"report_GLCM_NB.csv\", index= True, float_format='%.2f')"
   ],
   "id": "69702462d906c03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.1 Train without GLCM by Random Forest",
   "id": "2deabce685b2b0d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = SD_specs\n",
    "y = labels\n",
    "strKFold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100, 200],       # 树的数量\n",
    "    'randomforestclassifier__max_depth': [None],      # 树的最大深度 (None 表示不限制)\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],      # 内部节点分裂所需的最小样本数\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 3, 5]         # 叶节点所需的最小样本数\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9, stratify=y)\n",
    "scores = cross_val_score(model,X,y,cv=strKFold)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "grid_search_RF = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search_RF.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Best parameter: {grid_search_RF.best_params_}\")\n",
    "\n",
    "print(model)\n",
    "model.fit(X_train,y_train)\n",
    "score_res = model.score(X_train,y_train)\n",
    "print(\"The train score of model is : %f\"%score_res)\n",
    "score_res = model.score(X_test,y_test)\n",
    "print(\"The test score of model is : %f\"%score_res)\n",
    "y_pred = model.predict(X_test)\n",
    "img, report = drawer.show_confusion_matrix(y_test, y_pred)\n",
    "cv.imwrite('Plots/Prediction/prediction_None_RF.png', img)\n",
    "# 将report保存成本地文件\n",
    "pd.DataFrame(report).transpose().to_csv(\"report_None_RF.csv\", index= True, float_format='%.2f')"
   ],
   "id": "d20fd45c4d5a968b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.2 Train with GLCM by Random Forest",
   "id": "b347ff515d5657f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = specs_with_GLCM\n",
    "y = labels\n",
    "strKFold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100, 200],       # 树的数量\n",
    "    'randomforestclassifier__max_depth': [None],      # 树的最大深度 (None 表示不限制)\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],      # 内部节点分裂所需的最小样本数\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 3, 5]         # 叶节点所需的最小样本数\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9, stratify=y)\n",
    "scores = cross_val_score(model,X,y,cv=strKFold)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "\n",
    "grid_search_RF = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search_RF.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Best parameter: {grid_search_RF.best_params_}\")\n",
    "\n",
    "print(model)\n",
    "model.fit(X_train,y_train)\n",
    "score_res = model.score(X_train,y_train)\n",
    "print(\"The train score of model is : %f\"%score_res)\n",
    "score_res = model.score(X_test,y_test)\n",
    "print(\"The test score of model is : %f\"%score_res)\n",
    "y_pred = model.predict(X_test)\n",
    "img, report = drawer.show_confusion_matrix(y_test, y_pred)\n",
    "cv.imwrite('Plots/Prediction/prediction_GLCM_RF.png', img)\n",
    "# 将report保存成本地文件\n",
    "pd.DataFrame(report).transpose().to_csv(\"report_GLCM_RF.csv\", index= True, float_format='%.2f')"
   ],
   "id": "9fdd117419cbfa3f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
